{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ad87de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "from torch import nn\n",
    "import torch\n",
    "import sys\n",
    "import cv2\n",
    "sys.path.append('/home/nguyensolbadguy/Code_Directory/compression/models/yolov3') \n",
    "\n",
    "from yolov3.pytorchyolo import models,detect\n",
    "from yolov3.pytorchyolo.models import YOLOLayer,create_modules\n",
    "from yolov3.pytorchyolo.utils.utils import non_max_suppression,rescale_boxes\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4256dc4",
   "metadata": {},
   "source": [
    "Define the Yolov3 model by ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99c1a6a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Darknet(\n",
       "  (module_list): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (conv_0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_0): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (conv_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_1): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (conv_2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (conv_3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_3): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (shortcut_4): Sequential()\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (conv_5): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (batch_norm_5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_5): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (conv_6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_6): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (conv_7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_7): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (8): Sequential(\n",
       "      (shortcut_8): Sequential()\n",
       "    )\n",
       "    (9): Sequential(\n",
       "      (conv_9): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_9): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (10): Sequential(\n",
       "      (conv_10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_10): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (11): Sequential(\n",
       "      (shortcut_11): Sequential()\n",
       "    )\n",
       "    (12): Sequential(\n",
       "      (conv_12): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (batch_norm_12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_12): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (13): Sequential(\n",
       "      (conv_13): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_13): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (14): Sequential(\n",
       "      (conv_14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_14): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (15): Sequential(\n",
       "      (shortcut_15): Sequential()\n",
       "    )\n",
       "    (16): Sequential(\n",
       "      (conv_16): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_16): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (17): Sequential(\n",
       "      (conv_17): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_17): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (18): Sequential(\n",
       "      (shortcut_18): Sequential()\n",
       "    )\n",
       "    (19): Sequential(\n",
       "      (conv_19): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_19): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (20): Sequential(\n",
       "      (conv_20): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_20): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_20): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (21): Sequential(\n",
       "      (shortcut_21): Sequential()\n",
       "    )\n",
       "    (22): Sequential(\n",
       "      (conv_22): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_22): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (23): Sequential(\n",
       "      (conv_23): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_23): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (24): Sequential(\n",
       "      (shortcut_24): Sequential()\n",
       "    )\n",
       "    (25): Sequential(\n",
       "      (conv_25): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_25): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_25): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (26): Sequential(\n",
       "      (conv_26): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_26): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (27): Sequential(\n",
       "      (shortcut_27): Sequential()\n",
       "    )\n",
       "    (28): Sequential(\n",
       "      (conv_28): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_28): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_28): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (29): Sequential(\n",
       "      (conv_29): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_29): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_29): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (30): Sequential(\n",
       "      (shortcut_30): Sequential()\n",
       "    )\n",
       "    (31): Sequential(\n",
       "      (conv_31): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_31): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_31): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (32): Sequential(\n",
       "      (conv_32): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_32): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_32): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (33): Sequential(\n",
       "      (shortcut_33): Sequential()\n",
       "    )\n",
       "    (34): Sequential(\n",
       "      (conv_34): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_34): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_34): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (35): Sequential(\n",
       "      (conv_35): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_35): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_35): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (36): Sequential(\n",
       "      (shortcut_36): Sequential()\n",
       "    )\n",
       "    (37): Sequential(\n",
       "      (conv_37): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (batch_norm_37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_37): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (38): Sequential(\n",
       "      (conv_38): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_38): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (39): Sequential(\n",
       "      (conv_39): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_39): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_39): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (40): Sequential(\n",
       "      (shortcut_40): Sequential()\n",
       "    )\n",
       "    (41): Sequential(\n",
       "      (conv_41): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_41): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_41): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (42): Sequential(\n",
       "      (conv_42): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_42): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_42): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (43): Sequential(\n",
       "      (shortcut_43): Sequential()\n",
       "    )\n",
       "    (44): Sequential(\n",
       "      (conv_44): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_44): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_44): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (45): Sequential(\n",
       "      (conv_45): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_45): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_45): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (46): Sequential(\n",
       "      (shortcut_46): Sequential()\n",
       "    )\n",
       "    (47): Sequential(\n",
       "      (conv_47): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_47): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_47): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (48): Sequential(\n",
       "      (conv_48): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_48): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_48): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (49): Sequential(\n",
       "      (shortcut_49): Sequential()\n",
       "    )\n",
       "    (50): Sequential(\n",
       "      (conv_50): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_50): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_50): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (51): Sequential(\n",
       "      (conv_51): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_51): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_51): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (52): Sequential(\n",
       "      (shortcut_52): Sequential()\n",
       "    )\n",
       "    (53): Sequential(\n",
       "      (conv_53): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_53): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_53): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (54): Sequential(\n",
       "      (conv_54): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_54): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_54): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (55): Sequential(\n",
       "      (shortcut_55): Sequential()\n",
       "    )\n",
       "    (56): Sequential(\n",
       "      (conv_56): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_56): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_56): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (57): Sequential(\n",
       "      (conv_57): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_57): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_57): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (58): Sequential(\n",
       "      (shortcut_58): Sequential()\n",
       "    )\n",
       "    (59): Sequential(\n",
       "      (conv_59): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_59): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_59): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (60): Sequential(\n",
       "      (conv_60): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_60): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_60): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (61): Sequential(\n",
       "      (shortcut_61): Sequential()\n",
       "    )\n",
       "    (62): Sequential(\n",
       "      (conv_62): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (batch_norm_62): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_62): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (63): Sequential(\n",
       "      (conv_63): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_63): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_63): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (64): Sequential(\n",
       "      (conv_64): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_64): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_64): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (65): Sequential(\n",
       "      (shortcut_65): Sequential()\n",
       "    )\n",
       "    (66): Sequential(\n",
       "      (conv_66): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_66): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_66): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (67): Sequential(\n",
       "      (conv_67): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_67): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_67): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (68): Sequential(\n",
       "      (shortcut_68): Sequential()\n",
       "    )\n",
       "    (69): Sequential(\n",
       "      (conv_69): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_69): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_69): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (70): Sequential(\n",
       "      (conv_70): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_70): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_70): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (71): Sequential(\n",
       "      (shortcut_71): Sequential()\n",
       "    )\n",
       "    (72): Sequential(\n",
       "      (conv_72): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_72): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_72): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (73): Sequential(\n",
       "      (conv_73): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_73): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (74): Sequential(\n",
       "      (shortcut_74): Sequential()\n",
       "    )\n",
       "    (75): Sequential(\n",
       "      (conv_75): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_75): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_75): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (76): Sequential(\n",
       "      (conv_76): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_76): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (77): Sequential(\n",
       "      (conv_77): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_77): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_77): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (78): Sequential(\n",
       "      (conv_78): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_78): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_78): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (79): Sequential(\n",
       "      (conv_79): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_79): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_79): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (80): Sequential(\n",
       "      (conv_80): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_80): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_80): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (81): Sequential(\n",
       "      (conv_81): Conv2d(1024, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (82): Sequential(\n",
       "      (yolo_82): YOLOLayer(\n",
       "        (mse_loss): MSELoss()\n",
       "        (bce_loss): BCELoss()\n",
       "      )\n",
       "    )\n",
       "    (83): Sequential(\n",
       "      (route_83): Sequential()\n",
       "    )\n",
       "    (84): Sequential(\n",
       "      (conv_84): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_84): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_84): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (85): Sequential(\n",
       "      (upsample_85): Upsample()\n",
       "    )\n",
       "    (86): Sequential(\n",
       "      (route_86): Sequential()\n",
       "    )\n",
       "    (87): Sequential(\n",
       "      (conv_87): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_87): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_87): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (88): Sequential(\n",
       "      (conv_88): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_88): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_88): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (89): Sequential(\n",
       "      (conv_89): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_89): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_89): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (90): Sequential(\n",
       "      (conv_90): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_90): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_90): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (91): Sequential(\n",
       "      (conv_91): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_91): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_91): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (92): Sequential(\n",
       "      (conv_92): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_92): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_92): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (93): Sequential(\n",
       "      (conv_93): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (94): Sequential(\n",
       "      (yolo_94): YOLOLayer(\n",
       "        (mse_loss): MSELoss()\n",
       "        (bce_loss): BCELoss()\n",
       "      )\n",
       "    )\n",
       "    (95): Sequential(\n",
       "      (route_95): Sequential()\n",
       "    )\n",
       "    (96): Sequential(\n",
       "      (conv_96): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_96): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_96): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (97): Sequential(\n",
       "      (upsample_97): Upsample()\n",
       "    )\n",
       "    (98): Sequential(\n",
       "      (route_98): Sequential()\n",
       "    )\n",
       "    (99): Sequential(\n",
       "      (conv_99): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_99): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_99): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (100): Sequential(\n",
       "      (conv_100): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_100): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_100): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (101): Sequential(\n",
       "      (conv_101): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_101): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_101): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (102): Sequential(\n",
       "      (conv_102): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_102): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_102): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (103): Sequential(\n",
       "      (conv_103): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_103): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_103): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (104): Sequential(\n",
       "      (conv_104): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_104): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_104): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (105): Sequential(\n",
       "      (conv_105): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (106): Sequential(\n",
       "      (yolo_106): YOLOLayer(\n",
       "        (mse_loss): MSELoss()\n",
       "        (bce_loss): BCELoss()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.load_model('/home/nguyensolbadguy/Code_Directory/compression/models/yolov3/config/yolov3.cfg','/home/nguyensolbadguy/Code_Directory/compression/models/yolov3/weights/yolov3.weights')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a571fb7",
   "metadata": {},
   "source": [
    "Check the layers and output of each layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c27d8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(729, 1296, 3)\n",
      "[[5.3251965e+01 1.7344706e+01 7.9719135e+02 7.3750366e+02 9.9736142e-01\n",
      "  0.0000000e+00]\n",
      " [1.2074897e+03 4.7534967e+02 1.2929420e+03 6.9665808e+02 9.9536353e-01\n",
      "  0.0000000e+00]\n",
      " [6.2586298e+02 1.1301550e+02 1.1306825e+03 7.3140393e+02 9.7910422e-01\n",
      "  0.0000000e+00]\n",
      " [8.1113174e+01 9.0996696e+01 1.3527492e+02 1.5972826e+02 5.2961564e-01\n",
      "  3.2000000e+01]]\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"/home/nguyensolbadguy/Code_Directory/compression/models/yolov3/messi.jpg\")\n",
    "\n",
    "# Convert OpenCV bgr to rgb\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "print(img.shape)\n",
    "\n",
    "# Runs the YOLO model on the image\n",
    "boxes = detect.detect_image(model, img)\n",
    "\n",
    "print(boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1770cc83",
   "metadata": {},
   "source": [
    "Create sub module from layer 5 (layer 13 in the paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "797ad0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 output shape: torch.Size([1, 32, 416, 416])\n",
      "Layer 1 output shape: torch.Size([1, 64, 208, 208])\n",
      "Layer 2 output shape: torch.Size([1, 32, 208, 208])\n",
      "Layer 3 output shape: torch.Size([1, 64, 208, 208])\n",
      "Layer 4 output shape: torch.Size([1, 64, 208, 208])\n",
      "Layer 5 output shape: torch.Size([1, 128, 104, 104])\n",
      "Layer 6 output shape: torch.Size([1, 64, 104, 104])\n",
      "Layer 7 output shape: torch.Size([1, 128, 104, 104])\n",
      "Layer 8 output shape: torch.Size([1, 128, 104, 104])\n",
      "Layer 9 output shape: torch.Size([1, 64, 104, 104])\n",
      "Layer 10 output shape: torch.Size([1, 128, 104, 104])\n",
      "Layer 11 output shape: torch.Size([1, 128, 104, 104])\n",
      "Layer 12 output shape: torch.Size([1, 256, 52, 52])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.randn(1, 3, 416, 416).to(device)\n",
    "with torch.no_grad():\n",
    "    x = input_tensor\n",
    "    for i in range(13):  # layer 0 to 5\n",
    "        x = model.module_list[i](x)\n",
    "        print(f\"Layer {i} output shape: {x.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af4ca01",
   "metadata": {},
   "source": [
    "Create sub module from layer 5 (layer 13 in the paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b4dca5",
   "metadata": {},
   "source": [
    "Test the appropriate input to this submodule  \n",
    "We expect this submodule receives input with shape (B,218,H/4,W/4)  \n",
    "We set B=1 and H=416 in this test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "692cac50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], size=(0, 6))\n",
      "torch.Size([1, 256, 52, 52])\n"
     ]
    }
   ],
   "source": [
    "class PartialYOLO(nn.Module):\n",
    "    def __init__(self, full_model, start_idx,image_size):\n",
    "        super().__init__()\n",
    "        self.module_defs = full_model.module_defs\n",
    "        self.module_list = full_model.module_list    \n",
    "        self.start_idx = start_idx\n",
    "        self.yolo_layers = [layer[0]\n",
    "                            for layer in self.module_list if isinstance(layer[0], YOLOLayer)]\n",
    "        self.image_size = image_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        layer_outputs, yolo_outputs = {}, []\n",
    "        for i in range(self.start_idx, len(self.module_list)):\n",
    "            module_def = self.module_defs[i]\n",
    "            module = self.module_list[i]\n",
    "\n",
    "            if module_def[\"type\"] in [\"convolutional\", \"upsample\", \"maxpool\"]:\n",
    "                x = module(x)\n",
    "                if i == 12:\n",
    "                    F_tilde = x \n",
    "\n",
    "            elif module_def[\"type\"] == \"route\":\n",
    "                \n",
    "                layers = [int(l) for l in module_def[\"layers\"].split(\",\")]\n",
    "                layers = [l if l >= 0 else i + l for l in layers]\n",
    "                \n",
    "                try:\n",
    "                    route_tensors = [layer_outputs[l] for l in layers]\n",
    "                except KeyError as e:\n",
    "                    raise RuntimeError(f\"Route error at layer {i}: missing dependency {e}\")\n",
    "\n",
    "                x = torch.cat(route_tensors, dim=1)\n",
    "                \n",
    "                if \"groups\" in module_def:\n",
    "                    group_size = x.shape[1] // int(module_def[\"groups\"])\n",
    "                    group_id = int(module_def[\"group_id\"])\n",
    "                    x = x[:, group_size * group_id : group_size * (group_id + 1)]\n",
    "\n",
    "            elif module_def[\"type\"] == \"shortcut\":\n",
    "\n",
    "                from_idx = int(module_def[\"from\"])\n",
    "                shortcut_idx = i + from_idx if from_idx < 0 else from_idx\n",
    "\n",
    "                try:\n",
    "                    x = layer_outputs[i - 1] + layer_outputs[shortcut_idx]\n",
    "                except KeyError as e:\n",
    "                    raise RuntimeError(f\"Shortcut error at layer {i}: missing dependency {e}\")\n",
    "\n",
    "            elif module_def[\"type\"] == \"yolo\":\n",
    "                x = module[0](x, self.image_size)\n",
    "                yolo_outputs.append(x)\n",
    "\n",
    "            layer_outputs[i] = x\n",
    "\n",
    "        return F_tilde,torch.cat(yolo_outputs, 1)\n",
    "    \n",
    "\n",
    "input_tensor = torch.randn(1, 128, 104, 104).to(device)\n",
    "partial_model = PartialYOLO(model, start_idx=12,image_size=416).to(device)\n",
    "\n",
    "def detect_image(model, img_size=416, conf_thres=0.5, nms_thres=0.5):\n",
    "\n",
    "    F_tilde,out = model(input_tensor)\n",
    "    detections = non_max_suppression(out, conf_thres, nms_thres)\n",
    "    detections = rescale_boxes(detections[0], img_size, [416,416])\n",
    "    print(detections)\n",
    "    return F_tilde\n",
    "    \n",
    "F_tilde = detect_image(partial_model)\n",
    "print(F_tilde.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "98b0a2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Sequential(\n",
      "  (conv_12): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch_norm_12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_12): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '2', 'pad': '1', 'activation': 'leaky'}\n",
      "13\n",
      "Sequential(\n",
      "  (conv_13): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_13): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "14\n",
      "Sequential(\n",
      "  (conv_14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_14): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "15\n",
      "Sequential(\n",
      "  (shortcut_15): Sequential()\n",
      ")\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "16\n",
      "Sequential(\n",
      "  (conv_16): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_16): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "17\n",
      "Sequential(\n",
      "  (conv_17): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_17): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "18\n",
      "Sequential(\n",
      "  (shortcut_18): Sequential()\n",
      ")\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "19\n",
      "Sequential(\n",
      "  (conv_19): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_19): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "20\n",
      "Sequential(\n",
      "  (conv_20): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_20): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_20): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "21\n",
      "Sequential(\n",
      "  (shortcut_21): Sequential()\n",
      ")\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "22\n",
      "Sequential(\n",
      "  (conv_22): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_22): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "23\n",
      "Sequential(\n",
      "  (conv_23): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_23): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "24\n",
      "Sequential(\n",
      "  (shortcut_24): Sequential()\n",
      ")\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "25\n",
      "Sequential(\n",
      "  (conv_25): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_25): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_25): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "26\n",
      "Sequential(\n",
      "  (conv_26): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_26): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "27\n",
      "Sequential(\n",
      "  (shortcut_27): Sequential()\n",
      ")\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "28\n",
      "Sequential(\n",
      "  (conv_28): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_28): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_28): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "29\n",
      "Sequential(\n",
      "  (conv_29): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_29): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_29): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "30\n",
      "Sequential(\n",
      "  (shortcut_30): Sequential()\n",
      ")\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "31\n",
      "Sequential(\n",
      "  (conv_31): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_31): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_31): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "32\n",
      "Sequential(\n",
      "  (conv_32): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_32): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_32): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "33\n",
      "Sequential(\n",
      "  (shortcut_33): Sequential()\n",
      ")\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "34\n",
      "Sequential(\n",
      "  (conv_34): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_34): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_34): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "35\n",
      "Sequential(\n",
      "  (conv_35): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_35): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_35): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "36\n",
      "Sequential(\n",
      "  (shortcut_36): Sequential()\n",
      ")\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "37\n",
      "Sequential(\n",
      "  (conv_37): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch_norm_37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_37): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '2', 'pad': '1', 'activation': 'leaky'}\n",
      "38\n",
      "Sequential(\n",
      "  (conv_38): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_38): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "39\n",
      "Sequential(\n",
      "  (conv_39): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_39): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_39): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "40\n",
      "Sequential(\n",
      "  (shortcut_40): Sequential()\n",
      ")\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "41\n",
      "Sequential(\n",
      "  (conv_41): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_41): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_41): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "42\n",
      "Sequential(\n",
      "  (conv_42): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_42): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_42): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "43\n",
      "Sequential(\n",
      "  (shortcut_43): Sequential()\n",
      ")\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "44\n",
      "Sequential(\n",
      "  (conv_44): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_44): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_44): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "45\n",
      "Sequential(\n",
      "  (conv_45): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_45): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_45): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "46\n",
      "Sequential(\n",
      "  (shortcut_46): Sequential()\n",
      ")\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "47\n",
      "Sequential(\n",
      "  (conv_47): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_47): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_47): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "48\n",
      "Sequential(\n",
      "  (conv_48): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_48): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_48): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "49\n",
      "Sequential(\n",
      "  (shortcut_49): Sequential()\n",
      ")\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "50\n",
      "Sequential(\n",
      "  (conv_50): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_50): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_50): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "51\n",
      "Sequential(\n",
      "  (conv_51): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_51): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_51): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "52\n",
      "Sequential(\n",
      "  (shortcut_52): Sequential()\n",
      ")\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "53\n",
      "Sequential(\n",
      "  (conv_53): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_53): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_53): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "54\n",
      "Sequential(\n",
      "  (conv_54): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_54): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_54): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "55\n",
      "Sequential(\n",
      "  (shortcut_55): Sequential()\n",
      ")\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "56\n",
      "Sequential(\n",
      "  (conv_56): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_56): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_56): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "57\n",
      "Sequential(\n",
      "  (conv_57): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_57): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_57): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "58\n",
      "Sequential(\n",
      "  (shortcut_58): Sequential()\n",
      ")\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "59\n",
      "Sequential(\n",
      "  (conv_59): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_59): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_59): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "60\n",
      "Sequential(\n",
      "  (conv_60): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_60): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_60): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "61\n",
      "Sequential(\n",
      "  (shortcut_61): Sequential()\n",
      ")\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "62\n",
      "Sequential(\n",
      "  (conv_62): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch_norm_62): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_62): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '1024', 'size': '3', 'stride': '2', 'pad': '1', 'activation': 'leaky'}\n",
      "63\n",
      "Sequential(\n",
      "  (conv_63): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_63): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_63): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "64\n",
      "Sequential(\n",
      "  (conv_64): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_64): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_64): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '1024', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "65\n",
      "Sequential(\n",
      "  (shortcut_65): Sequential()\n",
      ")\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "66\n",
      "Sequential(\n",
      "  (conv_66): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_66): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_66): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "67\n",
      "Sequential(\n",
      "  (conv_67): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_67): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_67): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '1024', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "68\n",
      "Sequential(\n",
      "  (shortcut_68): Sequential()\n",
      ")\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "69\n",
      "Sequential(\n",
      "  (conv_69): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_69): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_69): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "70\n",
      "Sequential(\n",
      "  (conv_70): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_70): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_70): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '1024', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "71\n",
      "Sequential(\n",
      "  (shortcut_71): Sequential()\n",
      ")\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "72\n",
      "Sequential(\n",
      "  (conv_72): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_72): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_72): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "73\n",
      "Sequential(\n",
      "  (conv_73): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_73): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '1024', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "74\n",
      "Sequential(\n",
      "  (shortcut_74): Sequential()\n",
      ")\n",
      "{'type': 'shortcut', 'from': '-3', 'activation': 'linear'}\n",
      "75\n",
      "Sequential(\n",
      "  (conv_75): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_75): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_75): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "76\n",
      "Sequential(\n",
      "  (conv_76): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_76): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '1024', 'activation': 'leaky'}\n",
      "77\n",
      "Sequential(\n",
      "  (conv_77): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_77): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_77): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "78\n",
      "Sequential(\n",
      "  (conv_78): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_78): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_78): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '1024', 'activation': 'leaky'}\n",
      "79\n",
      "Sequential(\n",
      "  (conv_79): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_79): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_79): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '512', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "80\n",
      "Sequential(\n",
      "  (conv_80): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_80): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_80): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '1024', 'activation': 'leaky'}\n",
      "81\n",
      "Sequential(\n",
      "  (conv_81): Conv2d(1024, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': 0, 'size': '1', 'stride': '1', 'pad': '1', 'filters': '255', 'activation': 'linear'}\n",
      "82\n",
      "Sequential(\n",
      "  (yolo_82): YOLOLayer(\n",
      "    (mse_loss): MSELoss()\n",
      "    (bce_loss): BCELoss()\n",
      "  )\n",
      ")\n",
      "{'type': 'yolo', 'mask': '6,7,8', 'anchors': '10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326', 'classes': '80', 'num': '9', 'jitter': '.3', 'ignore_thresh': '.7', 'truth_thresh': '1', 'random': '1'}\n",
      "83\n",
      "Sequential(\n",
      "  (route_83): Sequential()\n",
      ")\n",
      "{'type': 'route', 'layers': '-4'}\n",
      "84\n",
      "Sequential(\n",
      "  (conv_84): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_84): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_84): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "85\n",
      "Sequential(\n",
      "  (upsample_85): Upsample()\n",
      ")\n",
      "{'type': 'upsample', 'stride': '2'}\n",
      "86\n",
      "Sequential(\n",
      "  (route_86): Sequential()\n",
      ")\n",
      "{'type': 'route', 'layers': '-1, 61'}\n",
      "87\n",
      "Sequential(\n",
      "  (conv_87): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_87): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_87): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "88\n",
      "Sequential(\n",
      "  (conv_88): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_88): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_88): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '512', 'activation': 'leaky'}\n",
      "89\n",
      "Sequential(\n",
      "  (conv_89): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_89): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_89): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "90\n",
      "Sequential(\n",
      "  (conv_90): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_90): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_90): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '512', 'activation': 'leaky'}\n",
      "91\n",
      "Sequential(\n",
      "  (conv_91): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_91): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_91): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '256', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "92\n",
      "Sequential(\n",
      "  (conv_92): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_92): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_92): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '512', 'activation': 'leaky'}\n",
      "93\n",
      "Sequential(\n",
      "  (conv_93): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': 0, 'size': '1', 'stride': '1', 'pad': '1', 'filters': '255', 'activation': 'linear'}\n",
      "94\n",
      "Sequential(\n",
      "  (yolo_94): YOLOLayer(\n",
      "    (mse_loss): MSELoss()\n",
      "    (bce_loss): BCELoss()\n",
      "  )\n",
      ")\n",
      "{'type': 'yolo', 'mask': '3,4,5', 'anchors': '10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326', 'classes': '80', 'num': '9', 'jitter': '.3', 'ignore_thresh': '.7', 'truth_thresh': '1', 'random': '1'}\n",
      "95\n",
      "Sequential(\n",
      "  (route_95): Sequential()\n",
      ")\n",
      "{'type': 'route', 'layers': '-4'}\n",
      "96\n",
      "Sequential(\n",
      "  (conv_96): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_96): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_96): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "97\n",
      "Sequential(\n",
      "  (upsample_97): Upsample()\n",
      ")\n",
      "{'type': 'upsample', 'stride': '2'}\n",
      "98\n",
      "Sequential(\n",
      "  (route_98): Sequential()\n",
      ")\n",
      "{'type': 'route', 'layers': '-1, 36'}\n",
      "99\n",
      "Sequential(\n",
      "  (conv_99): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_99): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_99): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "100\n",
      "Sequential(\n",
      "  (conv_100): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_100): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_100): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '256', 'activation': 'leaky'}\n",
      "101\n",
      "Sequential(\n",
      "  (conv_101): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_101): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_101): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "102\n",
      "Sequential(\n",
      "  (conv_102): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_102): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_102): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '256', 'activation': 'leaky'}\n",
      "103\n",
      "Sequential(\n",
      "  (conv_103): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (batch_norm_103): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_103): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '128', 'size': '1', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n",
      "104\n",
      "Sequential(\n",
      "  (conv_104): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch_norm_104): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_104): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': '1', 'size': '3', 'stride': '1', 'pad': '1', 'filters': '256', 'activation': 'leaky'}\n",
      "105\n",
      "Sequential(\n",
      "  (conv_105): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "{'type': 'convolutional', 'batch_normalize': 0, 'size': '1', 'stride': '1', 'pad': '1', 'filters': '255', 'activation': 'linear'}\n",
      "106\n",
      "Sequential(\n",
      "  (yolo_106): YOLOLayer(\n",
      "    (mse_loss): MSELoss()\n",
      "    (bce_loss): BCELoss()\n",
      "  )\n",
      ")\n",
      "{'type': 'yolo', 'mask': '0,1,2', 'anchors': '10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326', 'classes': '80', 'num': '9', 'jitter': '.3', 'ignore_thresh': '.7', 'truth_thresh': '1', 'random': '1'}\n"
     ]
    }
   ],
   "source": [
    "module_list = model.module_list\n",
    "module_def = model.module_defs\n",
    "for i in range(12, len(module_list)):\n",
    "    print(i)\n",
    "    print(module_list[i])\n",
    "    print(module_def[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1795aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BLIP2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
